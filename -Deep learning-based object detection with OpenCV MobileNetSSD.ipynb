{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning-based object detection with OpenCV MobileNet:SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the MobileNet SSD + deep neural network (dnn\n",
    " ) module in OpenCV to build our object detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrauct Arguments parse and parse the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap=argparse.ArgumentParser()\n",
    "\n",
    "ap.add_argument(\"--image\",required=True,help=\"path of the image\")\n",
    "ap.add_argument(\"--prototxt\",required=True,help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"--model\",required=True,help=\"path of caffe 'deploy' pretrained model\")\n",
    "ap.add_argument(\"--confidence\",required=True,help=\"minimum probabilty to filter weak predictions\")\n",
    "\n",
    "args=vars(ap.parse_args([\"--image\",r\"C:\\Users\\SRKT\\Desktop\\MibileNet_SSD_modle\\images\\example_05.jpg\",\n",
    "                        \"--prototxt\",r\"C:\\Users\\SRKT\\Desktop\\MibileNet_SSD_modle\\MobileNetSSD_deploy.prototxt.txt\",\n",
    "                        \"--model\",r\"C:\\Users\\SRKT\\Desktop\\MibileNet_SSD_modle\\MobileNetSSD_deploy.caffemodel\",\n",
    "                        \"--confidence\",\"0.5\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize class labels and bounding box colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect, then generate a set of bounding box colors for each class\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "COLORS=np.random.uniform(0,255,size=(len(CLASSES),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model\")\n",
    "\n",
    "net=cv2.dnn.readNetFromCaffe(args[\"prototxt\"],args[\"model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load our query image and prepare the blob\n",
    "#load the input image and construct an input blob for the image\n",
    "#by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "#(note: normalization is done via the authors of the MobileNet SSD\n",
    "#implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(args[\"image\"])\n",
    "(h,w)=image.shape[:2]\n",
    "\n",
    "blob=cv2.dnn.blobFromImage(cv2.resize(image,(300,300)),0.007843,(300, 300), 127.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we’ll pass this blob through the neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " pass the blob through the network and obtain the detections and\n",
    " predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] computing object detections ....\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] computing object detections ....\")\n",
    "\n",
    "net.setInput(blob)\n",
    "detections=net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[,frame,no of detections,[class id,class score,conf,x,y,h,w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 100, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s loop through our detections\n",
    "  and determine what and where the objects are in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] car : 99.43%\n",
      "[INFO] cat : 57.60%\n",
      "[INFO] dog : 61.78%\n",
      "[INFO] horse : 99.91%\n",
      "[INFO] person : 88.44%\n"
     ]
    }
   ],
   "source": [
    "#Looping through our detections\n",
    "# , first we extract the confidence\n",
    "for i in range(0,detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated with the\n",
    "    # prediction\n",
    "    confidence=detections[0,0,i,2]\n",
    "    \n",
    "    # filter out weak detections by ensuring the `confidence` is\n",
    "    # greater than the minimum confidence\n",
    "    if confidence>0.5:\n",
    "        \n",
    "        # extract the index of the class label from the `detections`,\n",
    "        # then compute the (x, y)-coordinates of the bounding box for\n",
    "        # the object\n",
    "        idx=int(detections[0,0,i,1])\n",
    "        box=detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (startX,startY,endX,endY)=box.astype('int')\n",
    "        \n",
    "        # we build a text label containing the CLASS name and the confidence\n",
    "        label=\"{} : {:.2f}%\".format(CLASSES[idx],confidence*100)\n",
    "        print(\"[INFO] {}\".format(label))\n",
    "        \n",
    "        cv2.rectangle(image,(startX,startY),(endX,endY),COLORS[idx],2)\n",
    "        y=startY-15 if startY-15>15 else startY+15\n",
    "        cv2.putText(image,label,(startX,y),cv2.FONT_HERSHEY_SIMPLEX,0.5,COLORS[idx],2)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"output\",image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
